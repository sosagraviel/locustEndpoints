provisioning: cloud
settings:
  artifacts-dir: build/%H%M%S
  default-executor: locust
  env:
    LOCAL_THREAD_COUNT: 1  # number of users/threads (assuming 20 peak concurrent users from 1000 users/hour)
    CLOUD_THREAD_COUNT: 1  # number of users/threads (assuming 20 peak concurrent users from 1000 users/hour)
    RAMP_UP: 5 # time for users to build from 0 to number of users/threads
    HOLD_FOR: 22
    THINK-TIME: 2000ms # delay between request to simulate human thinking
    TIME-OUT: 50s

execution:
  - scenario: elliegrid
    ramp-up: ${RAMP_UP}
    hold-for: ${HOLD_FOR}
    concurrency:
      local: ${LOCAL_THREAD_COUNT}
      cloud: ${CLOUD_THREAD_COUNT}
scenarios:
  chat_assessment:
    script: src/elliegrid.py
    default-address: "https://api.elliegrid.inhouse.decemberlabs.com"
modules:
  blazemeter:
    dedicated-ips: false
  cloud:
    token: "1974788aef91fd02ce2400ec:bc020485d1eedb7346d2a44370ede7a829d152f5c89f60113a91db17cfe722551a970919"
    account: 943147
    workspace: 960443
    project: 1092205
    report-name: Elliegrid
    test: Assessment flow
    browser-open: none
    public-report: true
    send-report-email: false
    upload-artifacts: false
reporting:
- module: console
- module: final-stats
  summary: true  # overall samples count and percent of failures
  percentiles: true  # display average times and percentiles
  failed-labels: true  # provides list of sample labels with failures
  test-duration: true  # provides test duration